<html>
    <head>
        <title>Webcam</title>
        <style>
                #container {
                    margin: 0px auto;
                    width: 500px;
                    height: 375px;
                    border: 10px #333 solid;
                }
                #videoElement {
                    top: 0;
                    left:0;
                    width: 500px;
                    height: 375px;
                    background-color: #666;
                }
                #overlay, .overlay {
                    position: absolute;
                    top: 0;
                    left: 0;
            }
        </style>
    </head>
    <body>
            <!-- <div id="container"> -->
            <canvas id="canvas" class="overlay"></canvas>
			<video id="videoElement"  autoplay muted>
  			<source src="http://localhost:8080/sream" type="video/ogg" />
</video>

          
                   
            <!-- </div> -->
            
        <!--<script src="js/jquery-2.1.1.min.js"></script>-->
		<script src="../resources/js/jquery.min.js"></script>
        <script src="../resources/js/face-api.js"></script>
        <script>

          $(document).ready(function(){
                let video = document.querySelector("#videoElement");
                
                setInterval(function(){
       			 console.log("Video src playing status "+video.playing);
       			 if(!video.playing){
       				 console.log("Video file is not playing...");
       				 video.load();
       				 video.play();
       			 }
     	        },5000);
       		
	       		Object.defineProperty(HTMLMediaElement.prototype, 'playing', {
	       		    get: function(){
	       		        return !!(this.currentTime > 0 && !this.paused && !this.ended && this.readyState > 2);
	       		    }
	       		})
       		
                let currentStream;
                let displaySize;

                let temp = []
				var labeledFaceDescriptors;
    
	   $("#videoElement").bind("loadeddata", function(){
                    displaySize = { width:this.scrollWidth, height: this.scrollHeight }

					async function load(){
						const MODEL_URL = '/models'
                        await faceapi.loadSsdMobilenetv1Model(MODEL_URL)
                        await faceapi.loadFaceLandmarkModel(MODEL_URL)
                        await faceapi.loadFaceRecognitionModel(MODEL_URL)
						const labels = ["2"]

                            labeledFaceDescriptors = await Promise.all(
                                labels.map(async label => {
                                    // fetch image data from urls and convert blob to HTMLImage element
                                    const imgname = `${label}.png`
									const imgUrl = imgname;
                                    const img = await faceapi.fetchImage(imgUrl)
                                    
                                    // detect the face with the highest score in the image and compute it's landmarks and face descriptor
                                    const fullFaceDescription = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor()
                                    
                                    if (!fullFaceDescription) {
                                    throw new Error(`no faces detected for ${label}`)
                                    }
                                    
                                    const faceDescriptors = [fullFaceDescription.descriptor]
                                    return new faceapi.LabeledFaceDescriptors(label, faceDescriptors)
                                })
                            );
					}
                    async function detect(){

                        let canvas = $("#canvas").get(0);

                        facedetection = setInterval(async () =>{

                            let fullFaceDescriptions = await faceapi.detectAllFaces(video).withFaceLandmarks().withFaceDescriptors()
                            let canvas = $("#canvas").get(0);
                            faceapi.matchDimensions(canvas, displaySize)

                            const fullFaceDescription = faceapi.resizeResults(fullFaceDescriptions, displaySize)
                            // faceapi.draw.drawDetections(canvas, fullFaceDescriptions)
                            const maxDescriptorDistance = 0.6
                            const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, maxDescriptorDistance)

                            const results = fullFaceDescriptions.map(fd => faceMatcher.findBestMatch(fd.descriptor))
							console.log(results);
                            results.forEach((bestMatch, i) => {
                                const box = fullFaceDescriptions[i].detection.box
                                const text = bestMatch.toString()
                                const drawBox = new faceapi.draw.DrawBox(box, { label: text })
                                drawBox.draw(canvas)
                            })

                        },300);

                        console.log(displaySize)
                    }
					load();
                    detect();
                    // console.log(this.scrollHeight);
                });   

 

          })  ;
		  
		  

            
        </script>
    </body>
</html>